{"posts":[{"title":"How to prevent duplicate SQS messages","text":"ProblemIn our system, queue processors must implement idempotency to prevent the double-processing of messages. Duplicate messages may arise in the following scenarios: Scheduler and Message Producer: The scheduler or message producer may be triggered multiple times, occasionally rerunning due to timeouts. Queue Management: If a lambda instance times out while processing a message, another instance may retrieve the same message if the visibility timeout is not properly set. This can have terrible consequences. We aim to avoid sending duplicate emails or messages to our customers, not to mention inadvertently delivering duplicate gift cards. So a generic idempotency mechanism is required. SolutionThe idea is straightforward: we will use a DynamoDB / Redis cache to store the message ID and the processing status. When a message is received, we will check the record to see if it has been processed. If it has, we will skip the message. If not, we will process it and update the cache. Considering our serverless architecture, DynamoDB is selected. Basically, there are three cases: Message first time processed: process the message. Message is being processed or has been processed: discard the message. Message processing failed: reprocess the message.To handle this case, we need to add a lock timeout to the record. If the message is still in processing status after the lock timeout, we give it another chance to be processed. Implementation Create a DynamoDB table message-processor. Itâ€™s a normal table with a primary key messageId. Implement a service with this interface:12345678910111213141516171819202122interface IMessageProcessorService { /** * Here use DynamoDB message-processor table as the fact store to decide if a message has been seen before * @param messageId unique identifier for each message * @param lockTimeoutInSeconds how long to lock the message for processing. It gives another chance to reprocess the message if it fails. * @returns boolean: true indicates the lock is acquired and should continue the processing. * false indicates the message is already being processed or being processed by another instance. */ acquireProcessingLock(messageId: string, lockTimeoutInSeconds: number): Promise&lt;boolean&gt;; /** * Mark the message as processed, preventing it from being processed again * @param messageId */ markMessageProcessed(messageId: string): Promise&lt;void&gt;; /** * Remove record of failed message processing, allowing it to be processed again * @param messageId */ releaseProcessingLock(messageId: string): Promise&lt;void&gt;;} The code snippet below shows how to implement the acquireProcessingLock method:(Never mind, weâ€™re using internal libraries to simplify the code) 1234567891011121314151617181920await this.store.replace( { _id: id, status: 'PROCESSING', timestamp: Date.now(), }, { condition: { $or: [ { _id: { $exists: false } }, // insert new record { $and: [ { timestamp: { $lt: Date.now() - lockTimeoutInSeconds * 1000 } }, { status: { $eq: 'PROCESSING' } }, ], }, ], }, },); At last, we enhance the existing message handler with the idempotency mechanism: 12345678910111213141516171819202122232425262728293031323334export const makeHandlerIdempotent = async &lt;T&gt;( handler: MessageHandler&lt;T&gt;, IdGenerator: (message: T) =&gt; string, { messageProcessorService, lockTimeoutInSeconds, logger, }: { logger: ILoggerService; messageProcessorService: IMessageProcessorService; lockTimeoutInSeconds: number; },): Promise&lt;MessageHandler&lt;T&gt;&gt; =&gt; { return async (message: T) =&gt; { const id = IdGenerator(message); const acquiredProcessingExclusiveLock = await messageProcessorService.acquireProcessingLock( id, lockTimeoutInSeconds, ); if (!acquiredProcessingExclusiveLock) { logger.info('processMessageIdempotent: message has already been processed', { message }); return; } try { const result = await handler(message); await messageProcessorService.markMessageProcessed(id); return result; } catch (error) { await messageProcessorService.releaseProcessingLock(id); throw error; } };}; ConclusionIt seems preventing duplicate messages in a distributed system is likely a common requirement.While implementing this idempotency mechanism, I found almost similar solution discussed How to prevent duplicate SQS Messages?.It was very helpful and offered clear explanations.","link":"/en/2024/05/11/How-to-prevent-duplicate-SQS-messages/"},{"title":"Auth0 lock issue","text":"This Friday when weâ€™re demo case, we noticed that it took a long time to display content on the Home page. It happened occasionally and soon we found it happened only when we had login into ULP but not the HOME page. Particularly, if you remove the cookie flag auth0.is.authenticated and refresh the page, you can reproduce it. You might have to wait for more than 10s. Reproduce and address potential codeThe first step is to check the network activity. The weird thing was: we got token at 1s roughly and it took about 100ms but the first GraphQL request was started at 11s. At first, I guessed probably it was blocked by some requests as there were so many requests online. The good thing is we could reproduce it locally. It proved that my guess was wrong after removing all unimportant requests. Then I began to log some methods with performance.mark and performance.measure. Soon we find the issue was caused by getTokenSilently API. It took more than 5s even the Network showed it took only 100ms. Look into SDKHereâ€™s what I found in that method: 1234567public async getTokenSilently() { options.scope = getUniqueScopes(this.DEFAULT_SCOPE, options.scope); await lock.acquireLock(GET_TOKEN_SILENTLY_LOCK_KEY, 5000); // 20 lines code lock.releaseLock(GET_TOKEN_SILENTLY_LOCK_KEY); return authResult.access_token;} We notice theyâ€™re using a lock which is a fresh thing in the FE. What if we get an exception, does it mean we have to wait for 5s? We might invoke this API a few times as we wanna always get a valid token. Itâ€™s why the GraphQL request began at 11s. Letâ€™s take a look at the source code and see if they fixed it. Yeah, they were aware of that issue and had already fixed it. And the new one looks like: 12345try { await lock.acquireLock(GET_TOKEN_SILENTLY_LOCK_KEY, 5000);} finally { await lock.releaseLock(GET_TOKEN_SILENTLY_LOCK_KEY);} Letâ€™s upgrade our package file and give it another try. ğŸ‰After a few moments â°. What? It still took 5s. Maybe I didnâ€™t update the right one, double-double-check: we did have the new package. There was something different: The first GraphQL began at 7s. Understand the Lock ğŸ”As we know, we donâ€™t the lock API in FE(Thereâ€™s an experimental API) They are using the browser-tabs-lock library. Itâ€™s used for preventing two tabs send request parallel. Basically, theyâ€™re using localStorage to implement the lock. Check if the Certain key is set in lcoalStorage, if not set it and acquire the lock successfully. Otherwise, listen to Storageâ€™s event or wait until timeout. After adding some log statements, I found there was an item in localStorage after redirecting back. Auth page is unable to access it. Therefore, the only reason was we didnâ€™t clean it before redirecting to the Auth page. However, before redirect to the Auth page, thereâ€™s nothing on the localStorage. Hereâ€™s related code. Have you noticed the problem? 123456789const isAuthenticated = await auth0FromHook.isAuthenticated();if (!isAuthenticated) { // Checked there was no item on lcoalStorage await auth0FromHook.loginWithRedirect({ appState: { targetUrl: window.location.href }, }); // Using location.assign}const token = await auth0FromHook.getTokenSilently();// ... Thereâ€™s nothing special with loginWithRedirect API. The root cause is the script doesnâ€™t stop after location change. The following code getTokenSilently is trying to acquire the lock but it doesnâ€™t have a chance to release the lock as the location was changed. Itâ€™s hard to debug it because we canâ€™t set a breakpoint or print any message after location change. Review of the bugWhen was the issue introduced In the beginning, we didnâ€™t have this issue as the Auth0 was not using the lock. We upgraded the version to 1.5.0 on 13/11/2019. It was a minor change and we didnâ€™t notice that. That means we had that issue since then. Why there was no alert from NewRelic This bug happens occasionally. It might just have a minor impact on the average time. The page load time fluctuates every day and only keep one weekâ€™s data. It might not be able to noticed in short term. Lesson from itRemember stop the script after location change.","link":"/en/2020/01/17/journeyman/Auth0-lock-issue/"},{"title":"Babel polyfill","text":"As a front developer, we should keep in mind what browsers are used by our customers. We say only modern browsers and IE 11 are supported, at least users wonâ€™t get an error on IE 11. Our config is : ['last 2 versions', 'ie &gt;= 11'] and hereâ€™s detailed browsers: last 2 versions. If you find your config is different from this one, please ensure your config is a superset of the above list. Mystery of BabelWith Babel, we could use new features of ES without worrying about compatibility. You must have got some error saying browser doesnâ€™t support it even youâ€™re using babel. Yeah, you might know we still have to take care of polyfill. Have you ever been confused about various babel packages? @babel/preset-env @babel/transform-runtime @babel/runtime @babel/polyfill To help you better understand those, Letâ€™s do some experiment.Letâ€™s say the source code looks like this: 123456789101112131415class A { method() {}}const arr = Array.from(['a']);const s = new Symbol();function* gen() { yield 3;}let array = [1, 2, 3, 4, 5, 6];array.includes(item =&gt; item &gt; 2);const promise = new Promise(); Please note: class arrow function let const are part of the syntax. Promise and Symbol and Array.from belong to global properties and static properties. [].includes is instance property. Preset-envFirstly, we just add preset-env and see whatâ€™s the outcode looks like 123[ &quot;@babel/env&quot;,] Outcode(output 1) â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸â¬‡ï¸ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&quot;use strict&quot;;var _marked =/*#__PURE__*/regeneratorRuntime.mark(gen);function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(&quot;Cannot call a class as a function&quot;); } }function _defineProperties(target, props) { for (var i = 0; i &lt; props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (&quot;value&quot; in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }var A =/*#__PURE__*/function () { function A() { _classCallCheck(this, A); } _createClass(A, [{ key: &quot;method&quot;, value: function method() {} }]); return A;}();var arr = Array.from(['a']);var s = new Symbol();function gen() { return regeneratorRuntime.wrap(function gen$(_context) { while (1) { switch (_context.prev = _context.next) { case 0: _context.next = 2; return 3; case 2: case &quot;end&quot;: return _context.stop(); } } }, _marked);}var array = [1, 2, 3, 4, 5, 6];array.includes(function (item) { return item &gt; 2;});var set = new Promise(); As we can see, babel transforms new syntax to the old one for us. But didnâ€™t change the static methods in the new feature. (Notice itâ€™s using global regeneratorRuntime ) If we specify targets only for modern browsers like below: 12345678[ &quot;@babel/env&quot;, { targets: { browsers: ['Chrome 70'], }, }] The outcode is almost same with source code. Itâ€™s not surprising. Letâ€™s move on. Now we set useBuiltIns as â€˜usageâ€™ 1234567891011[ '@babel/preset-env', { targets: { browsers: ['defaults'], }, useBuiltIns: 'usage', corejs: 3, // using useBuiltIns without declare corejs version will get warning. modules: false, },], We found babel imported a few files for us. 123456789import &quot;core-js/modules/es.symbol&quot;;import &quot;core-js/modules/es.symbol.description&quot;;import &quot;core-js/modules/es.array.from&quot;;import &quot;core-js/modules/es.array.includes&quot;;import &quot;core-js/modules/es.object.to-string&quot;;import &quot;core-js/modules/es.promise&quot;;import &quot;core-js/modules/es.string.iterator&quot;;import &quot;regenerator-runtime/runtime&quot;;// Below is same with output1 From now I set modules as false, so the outcode is using import rather than require. useBuiltIns has another option: â€˜entryâ€™. It wonâ€™t import polyfill for us. We still have to import polyfill by yourself but it will import specific files in terms of your target setting. 12import 'core-js/stable';import 'regenerator-runtime/runtime'; If in your entry files, you have the above code, it will transform to the below one. (It depends on your target browsers. Even you never use it in your code.) 123456import &quot;core-js/modules/es.symbol.description&quot;;import &quot;core-js/modules/es.symbol.async-iterator&quot;;import &quot;core-js/modules/es.array.flat&quot;;import &quot;core-js/modules/es.array.flat-map&quot;;....// very long Transform-runtimeLetâ€™s disable useBuiltIns and move on. Add plugins to babel config file: &quot;plugins&quot;: [&quot;@babel/plugin-transform-runtime&quot;] The outcode: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import _regeneratorRuntime from &quot;@babel/runtime/regenerator&quot;;import _classCallCheck from &quot;@babel/runtime/helpers/classCallCheck&quot;;import _createClass from &quot;@babel/runtime/helpers/createClass&quot;;var _marked =/*#__PURE__*/_regeneratorRuntime.mark(gen);var A =/*#__PURE__*/function () { function A() { _classCallCheck(this, A); } _createClass(A, [{ key: &quot;method&quot;, value: function method() {} }]); return A;}();var arr = Array.from(['a']);var s = new Symbol();function gen() { return _regeneratorRuntime.wrap(function gen$(_context) { while (1) { switch (_context.prev = _context.next) { case 0: _context.next = 2; return 3; case 2: case &quot;end&quot;: return _context.stop(); } } }, _marked);}var array = [1, 2, 3, 4, 5, 6];array.includes(function (item) { return item &gt; 2;});var promise = new Promise(); This outcode is a bit different from the previous. As the documentation, by default, it set regenerator as true. Besides, it replaced inline helper with the module. But it didnâ€™t import any polyfill files. Letâ€™s try other params: [&quot;@babel/plugin-transform-runtime&quot;, {&quot;corejs&quot;: 3 }] The out code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import _Promise from &quot;@babel/runtime-corejs3/core-js-stable/promise&quot;;import _includesInstanceProperty from &quot;@babel/runtime-corejs3/core-js-stable/instance/includes&quot;;import _regeneratorRuntime from &quot;@babel/runtime-corejs3/regenerator&quot;;import _Symbol from &quot;@babel/runtime-corejs3/core-js-stable/symbol&quot;;import _Array$from from &quot;@babel/runtime-corejs3/core-js-stable/array/from&quot;;import _classCallCheck from &quot;@babel/runtime-corejs3/helpers/classCallCheck&quot;;import _createClass from &quot;@babel/runtime-corejs3/helpers/createClass&quot;;var _marked =/*#__PURE__*/_regeneratorRuntime.mark(gen);var A =/*#__PURE__*/function () { function A() { _classCallCheck(this, A); } _createClass(A, [{ key: &quot;method&quot;, value: function method() {} }]); return A;}();var arr = _Array$from(['a']);var s = new _Symbol();function gen() { return _regeneratorRuntime.wrap(function gen$(_context) { while (1) { switch (_context.prev = _context.next) { case 0: _context.next = 2; return 3; case 2: case &quot;end&quot;: return _context.stop(); } } }, _marked);}var array = [1, 2, 3, 4, 5, 6];_includesInstanceProperty(array).call(array, function (item) { return item &gt; 2;});var promise = new _Promise(); Here you see: it helped us handle new global properties even instance properties in a different way. It was using internal methods, which means it wonâ€™t pollute prototype or global namespace. Itâ€™s commonly used in the development of the third library. Also, you might have already noticed, we should ensure the packages used in outcode is accessible. @babel/runtime or core-js or regenerator-runtime/runtime (@babel/polyfill has been deprecated. use core-js/stable and regenerator-runtime/runtime directly. ) Which one we should chooseHereâ€™s guide If we take a look at CRA create.js itâ€™s using @babel/plugin-transform-runtime to save on codesize and regenerator polyfill. In @babel/preset-env set useBuiltIns: 'entry', it means we should import polyfill by ourselves. Hereâ€™s detailed documentation: https://create-react-app.dev/docs/supported-browsers-features#supported-browsers For us, maybe the best way is aligning our solution to CRA. For the micro front end, the best way is to import polyfill in the shell entry, others donâ€™t need import twice. I know, even we import all polyfill files, it doesnâ€™t make much difference. Anyway, weâ€™re stepping into the right direction.","link":"/en/2019/08/25/journeyman/babel-polyfill-enigma/"},{"title":"A bug which should have been solved a week ago","text":"Recently, we have a DS ticket that said a user got banner error periodically on the home page. That means we got some BE errors on API requests. I checked NewRelic and nothing exception was found. I checked error logs on our server and only a few 500 errors. I canâ€™t find further information about these errors. So I believe it was caused by an unstable network or it might be caused. I was not working on that task. Until yesterday we were going to solve a cache memory issue and I still not realized that was caused by cache memory. After I had submitted that PR of fixing cache memory, I decided to look that DS ticket again. I notice thereâ€™s some clue. I could find banner errors on fullstory and that means we did get some request errors. Then I checked request logs on Cloudflare and here are unsuccessful requests. We should notice that not all the unsuccessful requests matter because some of them are from scanners and attackers. If we look into the intensive bar, we notice that most of the errors are 5** error. We got this error probably because of the unavailable server. Letâ€™s take a look at all 502 errors. Then I notice that the chart is highly correlated to our server up-down. So, That errors must be caused by the memory issue. Basically, weâ€™re caching the requests to microservices. The problem is the cache instance is infinite by default. https://github.com/apollographql/apollo-server/issues/2252 Misunderstand about zero downtimeAs we might know when weâ€™re deploying a new update. A new docker image will be created and we start up 2 new instances. Then the load balancer will refer to the new instances once they are healthy. Then itâ€™s safe for us to delete the old instances. I didnâ€™t take it seriously when I saw the containers were down and up. As I thought it should be looked after by AWS agents and we wonâ€™t have downtime. When I looked at the chart, I was further convinced. Look, before the old container is down, a new container is already up. Itâ€™s awesome! Unfortunately, we still got 502 errors. But Why? ğŸ¤” The reason is we were not closing the old container deliberately. The old container dead of using out of memory. During that time(might be a few seconds), the request was assigned to that old container. Self ReviewI didnâ€™t know that the max size is infinite in the beginning. I did find that memory was increasing a few weeks ago but I didnâ€™t take it seriously as the misunderstanding I mentioned above. I could do better is to solve it immediately. Two things to help to debug: Talk to the people who report that bug; Check everything in that task. Some tips of troubleshootingThe most important thing to debug is to restore the error. If we could reproduce it, usually itâ€™s easy to fix it. Basically, itâ€™s hard to debug occasional errors. Once we know some user info, we could check fullstory and see the original errors. Once we know the accurate time, we could check all the logs during that period. The last critical thing from this lesson is prepare it beforehand. Before any alerts are triggered, weâ€™d better understand what normal error we have. In the next few days, I get to watch the error logs of Cloudflare, Newrelic and ensure I understand every error.","link":"/en/2020/02/14/novice/cache-memory-issue/"}],"tags":[{"name":"AWS","slug":"AWS","link":"/en/tags/AWS/"},{"name":"SQS Processor","slug":"SQS-Processor","link":"/en/tags/SQS-Processor/"},{"name":"Serviceless","slug":"Serviceless","link":"/en/tags/Serviceless/"},{"name":"å‰ç«¯","slug":"å‰ç«¯","link":"/en/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Auth0","slug":"Auth0","link":"/en/tags/Auth0/"},{"name":"é”","slug":"é”","link":"/en/tags/%E9%94%81/"},{"name":"babel","slug":"babel","link":"/en/tags/babel/"},{"name":"troubleshooting","slug":"troubleshooting","link":"/en/tags/troubleshooting/"},{"name":"apollo-data-source","slug":"apollo-data-source","link":"/en/tags/apollo-data-source/"}],"categories":[{"name":"å®è·µæ€»ç»“","slug":"å®è·µæ€»ç»“","link":"/en/categories/%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/"}],"pages":[{"title":"About","text":"Fedeoo, å·¥ç¨‹å¸ˆï¼Œå·¥ä½œå‰7å¹´ä¸»è¦åšå‰ç«¯å¼€å‘ï¼Œè¿™ä¸¤å¹´å¼€å§‹åšå…¨æ ˆå¼€å‘ã€‚æ­£å€¼è€Œç«‹ä¹‹å¹´ï¼ŒæƒŸæ„¿å¤šå¤šè¯»äº›ä¹¦ï¼Œæ›´å¥½çš„è®¤çŸ¥è¿™ä¸ªä¸–ç•Œã€‚ é€‰é²¨é±¼å›¾çš„åŸå› æ˜¯ï¼šé²¨é±¼æ°¸ä¸åœæ­¢æ¸¸åŠ¨ï¼Œæé†’è‡ªå·±å­¦ä¹ æ°¸ä¸æ­¢æ­¥ã€‚ æ¯•ä¸šæ¸£æµªå·¥ä½œä¸¤å¹´ï¼Œä¹‹åè¥¿å‚å·¥ä½œä¸€æ®µæ—¶é—´ï¼Œç°å°±èŒæ‚‰å°¼ä¸€å®¶å°å‚ã€‚ åšå®¢ä¸»è¦æ˜¯æ”¾ä¸€äº›æŠ€æœ¯æ”¶è·ï¼Œè€ƒè™‘æ”¾å…¥æ›´å¤šçš„æŠ€æœ¯æ€è€ƒï¼Œå› ä¸ºå•çº¯å»è®²ä¸€ä¸ªæŠ€æœ¯ç‚¹ï¼Œè°·æ­Œå¾ˆå®¹æ˜“æ‰¾åˆ°å¾ˆæœ‰æ·±åº¦çš„æ–‡ç« ï¼Œæ²¡å¿…è¦åšæ¬è¿å·¥äº†ã€‚ ç”¨åšå®¢è®°å½•æˆé•¿ï¼ŒåšæŒå®šæœŸè‡ªçœã€‚åªæœ‰åœ¨é™ä¸‹æ¥æ€è€ƒæ—¶ï¼Œæ‰èƒ½å¥½å¥½çš„åçœå’Œæ£€è§†è‡ªå·±ã€‚","link":"/en/about/index.html"}]}